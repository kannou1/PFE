// ai-service/controllers/chat.controller.js
const { callLLM } = require("../services/ollama.service");
const { BASE_SYSTEM_PROMPT } = require("../prompts/system.prompt");
const { userDataPrompt } = require("../prompts/user.prompt");
const { detectIntent, fetchUserContext } = require("../services/chat.service");

exports.chat = async (req, res) => {
  try {
    console.log('ğŸŸ¢ ========== AI-SERVICE REQUEST START ==========');
    console.log('ğŸ“¥ Request body:', JSON.stringify(req.body, null, 2));
    console.log('ğŸ“¥ Headers:', req.headers.authorization ? 'âœ… Token present' : 'âŒ No token');
    
    const { message, userId } = req.body;

    if (!message) {
      return res.status(400).json({ error: "Message is required" });
    }

    if (!userId) {
      return res.status(400).json({ error: "userId is required" });
    }

    const token = req.headers.authorization?.replace('Bearer ', '');
    console.log('ğŸ”‘ Token:', token ? `${token.substring(0, 30)}...` : 'âŒ NO TOKEN');
    
    const messages = [{ role: "system", content: BASE_SYSTEM_PROMPT }];

    // Detect intent
    const intent = detectIntent(message);
    console.log(`ğŸ¤– Detected intent: "${intent}"`);

    // Fetch context
    if (token) {
      try {
        console.log(`ğŸ“¡ Fetching context for userId: ${userId}, intent: ${intent}`);
        const userContext = await fetchUserContext(userId, intent, token, message);
        
        console.log('ğŸ“Š ========== USER CONTEXT RECEIVED ==========');
        console.log(JSON.stringify(userContext, null, 2));
        console.log('ğŸ“Š ============================================');
        
        if (userContext && Object.keys(userContext).length > 0) {
          const userPrompt = userDataPrompt(userContext);
          console.log('ğŸ“ User prompt generated, length:', userPrompt.length);
          console.log('ğŸ“ First 500 chars:', userPrompt.substring(0, 500));
          
          messages.push({
            role: "system",
            content: userPrompt
          });
          console.log('âœ… User context added to messages');
        } else {
          console.warn('âš ï¸ User context is empty or null');
        }
      } catch (contextError) {
        console.error('âŒ Error fetching context:', contextError.message);
        console.error('Stack:', contextError.stack);
      }
    } else {
      console.warn('âš ï¸ No token - skipping context fetch');
    }

    messages.push({ role: "user", content: message });

    console.log(`ğŸ“¤ Total messages for LLM: ${messages.length}`);
    console.log('ğŸ“¤ Messages:', messages.map((m, i) => `${i}: ${m.role} (${m.content.length} chars)`));
    
    const reply = await callLLM(messages);

    console.log('âœ… LLM response received');
    console.log('ğŸŸ¢ ========== AI-SERVICE REQUEST END ==========');
    
    res.json({ reply });
    
  } catch (err) {
    console.error('âŒ ai-service error:', err.message);
    console.error('Stack:', err.stack);
    
    if (!res.headersSent) {
      res.status(503).json({ 
        error: "AI service error", 
        details: err.message 
      });
    }
  }
};
